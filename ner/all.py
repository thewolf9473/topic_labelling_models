# -*- coding: utf-8 -*-
"""ALL

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14s8QUTb6FYvioGvH2OsutE-Xk_yyhJWE

## adapted asr to csv
"""

import pandas as pd
f=open('/content/adapted_asr.txt','r')
data=f.readlines()
f.close()

val=[]
for i in data:
  arr=i.split(' ')
  callid=arr[0]
  trans=' '.join(arr[1:])
  val.append([callid,trans])
df=pd.DataFrame(val,columns=['CALLID','adaptedasr_trans'])

df.shape

df.head()



df1=pd.read_csv('yaml_extracted.csv')
df1.head()

for i , row in df1.iterrows():
  text=row['transcript']
  ner=row['ner']

  if isinstance(ner,str):
    ner=literal_eval(ner)
    newner= list((map(lambda x: x.lower(),ner)))
  if isinstance(text,str):
    text=text.lower()

  df1.at[i,'transcript']=text
  df1.at[i,'ner']=newner
df1.head()

newdf=pd.merge(df,df1,on='CALLID',how='left')
newdf.shape

newdf.to_csv('adapted_basic.csv',index=False)



"""## flair model analysis import"""

!pip install flair --quiet
!pip install conllu==4.4.2

from flair.data import Sentence
from flair.models import SequenceTagger
# load tagger
# flair/ner-english-ontonotes-large => onto notes
# flair/ner-english-large => conll
tagger = SequenceTagger.load("flair/ner-english-ontonotes-large")

df.to_csv('asrbaseline.csv',index=False)

import pandas as pd
df=pd.read_csv('/content/asr_results (baseline and boosted).csv')
df.head()

df=df[['CALLID','ASR','ASR_boosted','asr_ner','asr_boosted_ner']]

import numpy as np
df['asrboosted_person']=np.empty((len(df), 0)).tolist()
df['asrboosted_location']=np.empty((len(df), 0)).tolist()
df['asrboosted_time']=np.empty((len(df), 0)).tolist()
df.head()

print('STARTING')
p='ASR_boosted'
mp='asrboosted_person'
ml='asrboosted_location'
mt='asrboosted_time'

for index,row in df.iterrows():
  manual_p=[]
  manual_l=[]
  manual_t=[]

  id=row['CALLID']
  manual_text=row[p]
  if isinstance(manual_text,str):
    sentence = Sentence(manual_text)
    tagger.predict(sentence)

    for entity in sentence.get_spans('ner'):
      ner_entity=entity.text
      ner_type=str(entity.labels[0].value)


      if ner_type in  ['PERSON']:
        manual_p.append(ner_entity)
      
      if ner_type in  ['LOC','ORG','GPE']:
        manual_l.append(ner_entity)
      
      if ner_type in  ['DATE','TIME']:
        manual_t.append(ner_entity)
        
  df.at[index,mp]=manual_p
  df.at[index,ml]=manual_l
  df.at[index,mt]=manual_t

  print(f'{index}/{df.shape[0]} done √√')

print('ENDING')

df.head()

df.to_csv('asr_boosted.csv',index=False)

import pandas as pd
df=pd.read_csv('asr_boosted.csv')
df.head()

d=pd.read_csv('/content/yaml_new.csv')
d.head()

df1=pd.merge(df,d,on='CALLID',how='left')

print(df.shape,d.shape,df1.shape)

df1.to_csv('asr_boosted_new.csv',index=False)

"""## PRECISION RECALL F1 TP FP FN - METRIC RESULTS AND FREQ """

import pandas as pd
df=pd.read_csv('/content/new_manual.csv')
df.head()

import numpy as np
import string
df['tp']=np.empty((len(df), 0)).tolist()
df['fp']=np.empty((len(df), 0)).tolist()
df['fn']=np.empty((len(df), 0)).tolist()
df.head(2)

from ast import literal_eval
from difflib import SequenceMatcher
for index , row in df.iterrows():
  r=row['ner_time']
  h=row['manual_time']


  if isinstance(r,str):
    r=literal_eval(r)
  else:
    r=[]
  
  if isinstance(h,str):
    h=literal_eval(h)
  else:
    h=[]

  #h=[''.join(c for c in s if c not in string.punctuation) for s in h]

  FN= [item for item in r if item not in h]
  FP= [item for item in h if item not in r]
  TP= [x for x in r if x in h]

# r is ground truth
# h is pred 

  '''for i in r:
    for j in h:
      sim=SequenceMatcher(a=i,b=j).ratio()
      if sim>0.5:
        if j not in TP:
          TP.append(j)
        if i in FN:
          FN.remove(i)
        else:
          pass
        if j in FP:
          FP.remove(j)'''
                

  df.at[index,'fp']=FP
  df.at[index,'fn']=FN
  df.at[index,'tp']=TP

df.head()

p=[]
r=[]
f=[]
wer=[]
tpn=[]
fpn=[]
fnn=[]
tp1=0
fp1=0
fn1=0
for i , row in df.iterrows():
  manual=row['ner_time'] 
  if isinstance(manual,str):
    manual=literal_eval(manual)
  else:
    manual=[]

  tp=row['tp']
  fp=row['fp']
  fn=row['fn']
  #w=row['WER']

  tp=[x for x in tp if x != []]
  fp=[x for x in fp if x != []]
  fn=[x for x in fn if x != []]



  if len(manual)>0:
    tpn.append(tp)
    fpn.append(fp)
    fnn.append(fn)


    tp=len(tp)
    fp=len(fp)
    fn=len(fn)
    

    tp1+=tp
    fp1+=fp
    fn1+=fn

    try:
      precision=tp/(tp+fp)
    except:
      precision=0
    try:
      recall=tp/(tp+fn)
    except:
      recall=0
    try:
      f1=(2*precision*recall)/(precision+recall)
    except:
      f1=0
  
    p.append(precision)
    r.append(recall)
    f.append(f1)
    #wer.append(w)

from statistics import mean
print(tp1,fp1,fn1)
precision=tp1/(tp1+fp1)
recall=tp1/(tp1+fn1)
f1=(2*precision*recall)/(precision+recall)
print(precision,recall,f1)

tpn=[x for x in tpn if x != []]
tpn = [item for sublist in tpn for item in sublist]
fpn=[x for x in fpn if x != []]
fpn = [item for sublist in fpn for item in sublist]
fnn=[x for x in fnn if x != []]
fnn = [item for sublist in fnn for item in sublist]
print(len(tpn),len(fpn),len(fnn))

from collections import Counter
def s(dict1):
  sorted_dict = {}
  sorted_keys = sorted(dict1, key=dict1.get)  
  for w in sorted_keys:
    sorted_dict[w] = dict1[w]
  print(sorted_dict)

print(s(Counter(tpn)))
print()
print(s(Counter(fpn)))
print()
print(s(Counter(fnn)))



per=[]
loc=[]
ti=[]
for i , row in df.iterrows():
  p=row['ner_person']
  l=row['ner_location']
  t=row['ner_time']

  if isinstance(p,str):
    p=literal_eval(p)

  if isinstance(l,str):
    l=literal_eval(l)
  if isinstance(t,str):
    t=literal_eval(t)

  per.append(p)
  loc.append(l)
  ti.append(t)

a=[]
for i in per:
  for j in i:
    a.append(j)
print(f'{len(a)} person')
print(a)
a=[]
for i in loc:
  for j in i:
    a.append(j)
print(f'{len(a)} location')
print(a)
a=[]
for i in ti:
  for j in i:
    a.append(j)
print(f'{len(a)} time')
print(a)

166+101

